{
  "name": "Signify",
  "tagline": "Sign Language Recognition using Neural Networks",
  "body": "#**Welcome to Project Signify**\r\n\r\nProject Signify is a Computer Vision based Sign Language Recognition Device that relies on the Microsoft Kinect to identify Indian Sign Language Gestures. Our work classifies 3 gestures using Kinect for Windows (Global Feature Extraction) with the onboard RGB and Depth sensor cameras.\r\n\r\n\r\n\r\n# **What is the significance of Signify?**\r\n\r\n\r\nThis system could find widespread use in schools where the hearing impaired generally require an interpreter for translation. It can find use in gatherings where the audience belongs to the hearing impaired community and needs to effectively communicate without third party intervention. It can be reverse engineered to learn sign language based on the training gestures provided. \r\n\r\n\r\n\r\n# **Project Phase:**\r\n\r\nClassification of 3 gestures with **93.33% test accuracy** using both large margin classifiers and Neural Networks.\r\n\r\n[> **Click to view White Paper**]([Click here for the White Paper](https://drive.google.com/file/d/0BxcO5v3Bi80QeHFKdXE5cWY3ZUk/view?usp=sharing))\r\n\r\n\r\n# **The Development Team**\r\n@surajpaib , LinkedIn Profile: \r\n\r\n@nayan-mehta , LinkedIn Profile:\r\n\r\n@deepthitv , LinkedIn Profile:\r\n\r\n@KohliP , LinkedIn Profile:\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}